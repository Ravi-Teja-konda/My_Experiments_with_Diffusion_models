
# Experiments_with_image_generation_diffusion_models
This is repository is a just an experiment with multiple image generation diffusion models.

Currently we have experimented with DALL-E-2 furthermore, we will be adding the results and analysis of other models 
like stable diffusion, Imagen, mid journey and others here.

## DALL-E-2 
Here in DALL-E in order to generate a high quality realistic image a detailed description of the image we want to generate should be provided.
Basically we call the description as prompt in dall-e, prompt in dall-e is limited to 400 words and has the strict censoring to hate, violence, explicit and other content.

For more info on dalle-2 content policy please refer content policy

[arbitrary case-insensitive reference text]: https://labs.openai.com/policies/content-policy#:~:text=In%20your%20usage%2C%20you%20must,promoting%20hate%20based%20on%20identity



### Writing good prompt
In order to get better results adding adjectives and keeping it simple helps us.But if we want to generate a specific image adding detailed description to the prompt will give better results. adding the terms like hyper-realstic, high resolution, and lighting , photography style, lens type will give good output.

Here are images generated with DALL-E-2 and tweaked with ARC face restoration AI.













